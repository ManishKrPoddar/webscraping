To get data from the previous code, there are two methods:



First Method

Here is the parse function that you can use to get URLs and title for example:

    def parse_book(self, response):
        title = response.css('h1::text').extract_first()
        url = response.request.url
        yield {'title': title, 'url':url}
As you can see, all what you need is to use is  response.request.url to get the URL of the current request. Actually, you could even use response.url to get the URL from the response, but the former would be more accurate in the case there are redirections. For this website, both would give the same result.

Yes, you should use this code *without* defining anything in items.py. Using a dictionary should be the same as using items.



Second Method

If you rather want to use items, your way should work as well. Add the following to items.py under  class BooksCrawlerItem(scrapy.Item) 

    url = scrapy.Field()
    title = scrapy.Field()
Then in the books.py import from books_crawler.items import BooksCrawlerItem changing the names based on your project.

Then add the following parse function:

    def parse_book(self, response):
        items = BooksCrawlerItem()
        title = response.css('h1::text').extract_first()
        url = response.request.url
    
        items['title'] = title
        items['url'] = url
        yield items
The items method should work as well. But do not use parts of one way in the other way to avoid unexpected results.



If you have questions, please feel free to send them to the Q&A section.
