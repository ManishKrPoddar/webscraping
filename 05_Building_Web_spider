scrapy shell http://quotes.toscrape.com
quotes = response.xpath('//*[@class="quote"]')
quote = quotes[0]
quote.extract()
quote.xpath()
quote.xpath('//a')
quote.xpath('.//a')
quote.xpath('.//*[@class="text"]/text()').extract_first()
quote.xpath('.//*[@class="author"]/text()').extract_first()
for quote in quotes:
	text = quote.xpath('.//*[@class="text"]/text()').extract_first()
	author = quote.xpath('.//*[@class="author"]/text()').extract_first()
	tags = quote.xpath('.//*[@itemprop="keywords"]/@content').extract_first()

#Part 2
print '\n'
print text
print author
print tags
print '\n'
scrapy crawl quotes
# To go to next page
go to terminal

response.xpath('//*[@class="next"]/a/@href').extract_first()

next_page_url = response.xpath('//*[@class="next"]/a/@href').extract_first()
absolute_next_page_url = response.urljoin(next_page_url)
yield scrapy.Request(absolute_next_page_url)

scrapy crawl quotes


for quote in quotes:
	text = quote.xpath('.//*[@class="text"]/text()').extract_first()
	author = quote.xpath('.//*[@class="author"]/text()').extract_first()
	tags = quote.xpath('.//*[@itemprop="keywords"]/@content').extract_first()
	print '\n'
	print text
	print author
	print tags
	print '\n'
	next_page_url = response.xpath('//*[@class="next"]/a/@href').extract_first()
	absolute_next_page_url = response.urljoin(next_page_url)
	yield scrapy.Request(absolute_next_page_url)
	
# -*- coding: utf-8 -*-
import scrapy


class QuotesSpider(scrapy.Spider):
    name = "quotes"
    allowed_domains = ["quotes.toscrape.com"]
    start_urls = (
        'http://quotes.toscrape.com/',
    )

    def parse(self, response):
        quotes = response.xpath('//*[@class="quote"]')
        for quote in quotes:
            text = quote.xpath('.//*[@class="text"]/text()').extract_first()
            author = quote.xpath('.//*[@itemprop="author"]/text()').extract_first()
            tags = quote.xpath('.//*[@itemprop="keywords"]/@content').extract_first()

            yield{'Text': text,
                  'Author': author,
                  'Tags': tags}

        next_page_url = response.xpath('//*[@class="next"]/a/@href').extract_first()
        absolute_next_page_url = response.urljoin(next_page_url)
        yield scrapy.Request(absolute_next_page_url)

